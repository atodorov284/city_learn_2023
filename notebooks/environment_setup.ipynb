{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn.agents.base import Agent as RandomAgent\n",
    "from citylearn.agents.rbc import HourRBC\n",
    "from citylearn.agents.sac import SAC\n",
    "from citylearn.agents.q_learning import TabularQLearning\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_evaluation(evaluation_data: dict) -> pd.DataFrame:\n",
    "    kpis = pd.DataFrame.from_dict(\n",
    "        evaluation_data, orient=\"index\", columns=[\"value\", \"display_name\", \"weight\"]\n",
    "    )\n",
    "    kpis_reset = kpis.reset_index().rename(columns={\"index\": \"metric\"})\n",
    "    return kpis_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\coding\\RLP\\city_learn_2023\\.venv\\lib\\site-packages\\citylearn\\dynamics.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(self.filepath)['model_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "root_directory = Path(\"../data/citylearn_challenge_2023_phase_1\")\n",
    "schema_path = root_directory / \"schema.json\"\n",
    "env = CityLearnEnv(schema=schema_path, root_directory=root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomAgent(env)\n",
    "\n",
    "observations = env.reset()\n",
    "random_rewards=[]\n",
    "\n",
    "while not env.done:\n",
    "    actions = random_model.predict(observations)\n",
    "    observations, reward, info, done = env.step(actions)\n",
    "    random_rewards.append(reward)\n",
    "\n",
    "random_agent_data = random_model.env.evaluate_citylearn_challenge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'format_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mformat_evaluation\u001b[49m(model\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mevaluate_citylearn_challenge())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'format_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "format_evaluation(model.env.evaluate_citylearn_challenge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\coding\\RLP\\city_learn_2023\\.venv\\lib\\site-packages\\citylearn\\dynamics.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(self.filepath)['model_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "env = CityLearnEnv(\n",
    "    schema=schema_path, root_directory=root_directory, central_agent=True\n",
    ")\n",
    "model = SAC(env)\n",
    "\n",
    "# train\n",
    "rewards = model.learn(episodes=3, deterministic_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\coding\\RLP\\city_learn_2023\\.venv\\lib\\site-packages\\citylearn\\dynamics.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(self.filepath)['model_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "env = CityLearnEnv(\n",
    "    schema=schema_path, root_directory=root_directory, central_agent=False\n",
    ")\n",
    "decentral_model = SAC(env)\n",
    "\n",
    "# train\n",
    "decentral_rewards = model.learn(episodes=3, deterministic_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\coding\\RLP\\city_learn_2023\\.venv\\lib\\site-packages\\citylearn\\dynamics.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(self.filepath)['model_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "observations= env.reset()\n",
    "\n",
    "rewards = []\n",
    "while not env.done:\n",
    "    actions= model.predict(observations, deterministic=True)\n",
    "    observations, reward, _, _= env.step(actions)\n",
    "    rewards.append(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_45348\\337779442.py:26: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "# Smooth the rewards using a uniform filter\n",
    "smoothed_rewards = uniform_filter1d(rewards, size=25, axis=0)  # Adjust size for smoothing level\n",
    "smoothed_decentral_rewards = uniform_filter1d(decentral_rewards, size=25, axis=0)\n",
    "\n",
    "# Plot the smoothed rewards and random rewards\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "plt.plot(rewards, label='Smoothed Rewards Centralized SAC', color='green', linewidth=2)  # Plot smoothed rewards\n",
    "plt.plot(decentral_rewards, label='Smoothed Rewards Decentralized SAC', color='blue', linewidth=2)  # Plot smoothed random rewards\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Centralized SAC vs. Decentralized SAC Rewards Over Time\", fontsize=16, fontweight='bold')  # Title with larger font size and bold\n",
    "plt.xlabel(\"Time Step\", fontsize=14)  # X-axis label with larger font size\n",
    "plt.ylabel(\"Reward\", fontsize=14)  # Y-axis label with larger font size\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(visible=True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig(\"smoothed_rewards_comparison.png\", dpi=300)  # Save with higher resolution\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>display_name</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carbon_emissions_total</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>Carbon emissions</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discomfort_proportion</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>Unmet hours</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ramping_average</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>Ramping</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily_one_minus_load_factor_average</td>\n",
       "      <td>0.931545</td>\n",
       "      <td>Load factor</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily_peak_average</td>\n",
       "      <td>0.920273</td>\n",
       "      <td>Daily peak</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_peak_average</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>All-time peak</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one_minus_thermal_resilience_proportion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thermal resilience</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>power_outage_normalized_unserved_energy_total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unserved energy</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>average_score</td>\n",
       "      <td>0.586544</td>\n",
       "      <td>Score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          metric     value  \\\n",
       "0                         carbon_emissions_total  0.961905   \n",
       "1                          discomfort_proportion  0.712610   \n",
       "2                                ramping_average  0.887045   \n",
       "3            daily_one_minus_load_factor_average  0.931545   \n",
       "4                             daily_peak_average  0.920273   \n",
       "5                            annual_peak_average  0.948750   \n",
       "6        one_minus_thermal_resilience_proportion       NaN   \n",
       "7  power_outage_normalized_unserved_energy_total       NaN   \n",
       "8                                  average_score  0.586544   \n",
       "\n",
       "         display_name  weight  \n",
       "0    Carbon emissions   0.100  \n",
       "1         Unmet hours   0.300  \n",
       "2             Ramping   0.075  \n",
       "3         Load factor   0.075  \n",
       "4          Daily peak   0.075  \n",
       "5       All-time peak   0.075  \n",
       "6  Thermal resilience   0.150  \n",
       "7     Unserved energy   0.150  \n",
       "8               Score     NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_evaluation(model.env.evaluate_citylearn_challenge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
